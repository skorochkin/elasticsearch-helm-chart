---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: "{{ template "name" . }}"
  labels:
    release: {{ .Release.Name | quote }}
    chart: "{{ .Chart.Name }}"
    app: "{{ template "name" . }}"
  # annotations: {}
spec:
  serviceName: "{{ template "name" . }}"
  selector:
    matchLabels:
      app: "{{ template "name" . }}"
  replicas: {{ .Values.replicas }}
  podManagementPolicy: {{ .Values.podManagementPolicy }}
  updateStrategy:
    type: {{ .Values.updateStrategy }}
  volumeClaimTemplates:
  - metadata:
      name: "{{ template "name" . }}"
      labels:
        release: {{ .Release.Name | quote }}
        chart: "{{ .Chart.Name }}"
        app: "{{ template "name" . }}"
      annotations: {}
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 5Gi
  template:
    metadata:
      name: "{{ template "name" . }}"
      labels:
        release: {{ .Release.Name | quote }}
        chart: "{{ .Chart.Name }}"
        app: "{{ template "name" . }}"
      # annotations: {}
    spec:
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      affinity:
      {{- if eq .Values.antiAffinity "hard" }}
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - "{{ template "name" .}}"
            topologyKey: {{ .Values.antiAffinityTopologyKey }}
      {{- else if eq .Values.antiAffinity "soft" }}
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: {{ .Values.antiAffinityTopologyKey }}
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - "{{ template "name" . }}"
      {{- end }}
      terminationGracePeriodSeconds: {{ .Values.terminationGracePeriod }}
      enableServiceLinks: {{ .Values.enableServiceLinks }}
      initContainers:
      - name: configure-sysctl
        securityContext:
          runAsUser: 0
          privileged: true
        image: "{{ .Values.image }}:{{ .Values.imageTag }}"
        imagePullPolicy: "{{ .Values.imagePullPolicy }}"
        command: [
          "sysctl",
          "-w",
          "vm.max_map_count={{ .Values.sysctlVmMaxMapCount}}"
        ]
        resources:
          limits:
            cpu: "25m"
            # memory: "128Mi"
          requests:
            cpu: "25m"
            memory: "128Mi"
      containers:
      - name: "{{ template "name" . }}"
        securityContext:
          runAsUser: 1000
          capabilities:
            drop:
              - ALL
          runAsNonRoot: true
        image: "{{ .Values.image }}:{{ .Values.imageTag }}"
        imagePullPolicy: "{{ .Values.imagePullPolicy }}"
        readinessProbe:
          exec:
            command:
              - sh
              - -c
              - |
                #!/usr/bin/env bash -e
                # If the node is starting up wait for the cluster to be ready (request params: "{{ .Values.clusterHealthCheckParams }}" )
                # Once it has started only check that the node itself is responding
                START_FILE=/tmp/.es_start_file
                # Disable nss cache to avoid filling dentry cache when calling curl
                # This is required with Elasticsearch Docker using nss < 3.52
                export NSS_SDB_USE_CACHE=no
                http () {
                  local path="${1}"
                  local args="${2}"
                  set -- -XGET -s
                  if [ "$args" != "" ]; then
                    set -- "$@" $args
                  fi
                  if [ -n "${ELASTIC_USERNAME}" ] && [ -n "${ELASTIC_PASSWORD}" ]; then
                    set -- "$@" -u "${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}"
                  fi
                  curl --output /dev/null -k "$@" "{{ .Values.protocol }}://127.0.0.1:{{ .Values.httpPort }}${path}"
                }
                if [ -f "${START_FILE}" ]; then
                  echo 'Elasticsearch is already running, lets check the node is healthy'
                  HTTP_CODE=$(http "/" "-w %{http_code}")
                  RC=$?
                  if [[ ${RC} -ne 0 ]]; then
                    echo "curl --output /dev/null -k -XGET -s -w '%{http_code}' \${BASIC_AUTH} {{ .Values.protocol }}://127.0.0.1:{{ .Values.httpPort }}/ failed with RC ${RC}"
                    exit ${RC}
                  fi
                  # ready if HTTP code 200, 503 is tolerable if ES version is 6.x
                  if [[ ${HTTP_CODE} == "200" ]]; then
                    exit 0
                  else
                    echo "curl --output /dev/null -k -XGET -s -w '%{http_code}' \${BASIC_AUTH} {{ .Values.protocol }}://127.0.0.1:{{ .Values.httpPort }}/ failed with HTTP code ${HTTP_CODE}"
                    exit 1
                  fi
                else
                  echo 'Waiting for elasticsearch cluster to become ready (request params: "{{ .Values.clusterHealthCheckParams }}" )'
                  if http "/_cluster/health?{{ .Values.clusterHealthCheckParams }}" "--fail" ; then
                    touch ${START_FILE}
                    exit 0
                  else
                    echo 'Cluster is not yet ready (request params: "{{ .Values.clusterHealthCheckParams }}" )'
                    exit 1
                  fi
                fi
          failureThreshold: 3
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 3
          timeoutSeconds: 5
        ports:
        - containerPort: {{ .Values.httpPort }}
          name: http
        - containerPort: {{ .Values.transportPort }}
          name: transport
        resources:
          requests:
            cpu: 0.25
          limits:
            cpu: 1
        env:
          - name: node.name
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: cluster.name
            value: "{{ .Values.clusterName }}"
          - name: cluster.initial_master_nodes
            value: "{{ template "endpoints" . }}"
          - name: discovery.seed_hosts
            value: "{{ template "name" . }}"
          - name: ES_JAVA_OPTS
            value: -Xms256m -Xmx256m
          - name: node.master
            value: "true"
          - name: node.ingest
            value: "true"
          - name: node.data
            value: "true"
          - name: network.host
            value: "{{ .Values.networkHost }}"
          - name: PROCESSORS
            valueFrom:
              resourceFieldRef:
                resource: limits.cpu
        volumeMounts:
          - name: "{{ template "name" . }}"
            mountPath: /usr/share/elasticsearch/data
